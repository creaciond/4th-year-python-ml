{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные как они есть в csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = \"./data/labeledEligibilitySample1000000.csv\"\n",
    "df = pd.read_table(df_raw, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переименуем колонки для понятности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({0: \"label\", 1: \"description\"}, axis=\"columns\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные данные:\n",
    "\n",
    "- у колонки с label уберём лишнее и пометим её как категорию,\n",
    "\n",
    "- колонку с описанием разделим на interventions и conditions,\n",
    "\n",
    "- interventions пометим как категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_label(label):\n",
    "    return label[-1]\n",
    "\n",
    "def extract_interventions(full_description):\n",
    "    interventions = full_description.split(\" . \")[0]\n",
    "    interventions = interventions.replace(\"study interventions are \", \"\")\n",
    "    return interventions\n",
    "\n",
    "def extract_conditions(full_description):\n",
    "    return full_description.split(\" . \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"label\"].apply(clean_label).astype(\"int\")\n",
    "df[\"interventions\"] = df[\"description\"].apply(extract_interventions).astype(\"category\")\n",
    "df[\"conditions\"] = df[\"description\"].apply(extract_conditions)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все диагнозы положим в отдельную колонку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_diagnosis(condition):\n",
    "    if \"diagnosis\" in condition:\n",
    "        return condition[0:condition.find(\"diagnosis\")-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"diagnosis\"] = df[\"conditions\"].apply(extract_diagnosis)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем `conditions`: оставим только значащие слова и обработаем их стеммером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stops = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conditions(conditions_raw):\n",
    "    conditions_norm = []\n",
    "    non_stops = [token for token in word_tokenize(conditions_raw)\n",
    "                if token not in stops]\n",
    "    for token in non_stops:\n",
    "        conditions_norm.append(stemmer.stem(token))\n",
    "    return \" \".join(conditions_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df[\"conditions parsed\"] = df[\"conditions\"].apply(parse_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайные решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1968)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"random label\"] = [random.choice([0, 1]) for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4998069999982946"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df[\"random label\"], df[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions_encoder = LabelEncoder()\n",
    "df[\"interventions\"] = interventions_encoder.fit_transform(df[\"interventions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_encoder = LabelEncoder()\n",
    "df[\"diagnosis\"].fillna(\"no diagnosis\", inplace=True)\n",
    "df[\"diagnosis\"] = diagnosis_encoder.fit_transform(df[\"diagnosis\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "      <th>interventions</th>\n",
       "      <th>conditions</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>conditions parsed</th>\n",
       "      <th>random label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>study interventions are recombinant CD40-ligan...</td>\n",
       "      <td>14650</td>\n",
       "      <td>melanoma skin diagnosis and no active cns meta...</td>\n",
       "      <td>4672</td>\n",
       "      <td>melanoma skin diagnosi activ cns metastas ct s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>study interventions are Liposomal doxorubicin ...</td>\n",
       "      <td>6744</td>\n",
       "      <td>colorectal cancer diagnosis and cardiovascular</td>\n",
       "      <td>1743</td>\n",
       "      <td>colorect cancer diagnosi cardiovascular</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>study interventions are BI 836909 . multiple m...</td>\n",
       "      <td>1433</td>\n",
       "      <td>multiple myeloma diagnosis and indwelling cent...</td>\n",
       "      <td>5033</td>\n",
       "      <td>multipl myeloma diagnosi indwel central venous...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>study interventions are Immunoglobulins . recu...</td>\n",
       "      <td>5912</td>\n",
       "      <td>recurrent fallopian tube carcinoma diagnosis a...</td>\n",
       "      <td>6949</td>\n",
       "      <td>recurr fallopian tube carcinoma diagnosi patie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>study interventions are Paclitaxel . stage ova...</td>\n",
       "      <td>8694</td>\n",
       "      <td>stage ovarian cancer diagnosis and patients mu...</td>\n",
       "      <td>8630</td>\n",
       "      <td>stage ovarian cancer diagnosi patient must rec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        description  interventions  \\\n",
       "0      0  study interventions are recombinant CD40-ligan...          14650   \n",
       "1      0  study interventions are Liposomal doxorubicin ...           6744   \n",
       "2      0  study interventions are BI 836909 . multiple m...           1433   \n",
       "3      0  study interventions are Immunoglobulins . recu...           5912   \n",
       "4      0  study interventions are Paclitaxel . stage ova...           8694   \n",
       "\n",
       "                                          conditions  diagnosis  \\\n",
       "0  melanoma skin diagnosis and no active cns meta...       4672   \n",
       "1     colorectal cancer diagnosis and cardiovascular       1743   \n",
       "2  multiple myeloma diagnosis and indwelling cent...       5033   \n",
       "3  recurrent fallopian tube carcinoma diagnosis a...       6949   \n",
       "4  stage ovarian cancer diagnosis and patients mu...       8630   \n",
       "\n",
       "                                   conditions parsed  random label  \n",
       "0  melanoma skin diagnosi activ cns metastas ct s...             0  \n",
       "1            colorect cancer diagnosi cardiovascular             0  \n",
       "2  multipl myeloma diagnosi indwel central venous...             1  \n",
       "3  recurr fallopian tube carcinoma diagnosi patie...             0  \n",
       "4  stage ovarian cancer diagnosi patient must rec...             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.to_csv(\"./data/labeledEligibilitySample_parsed.csv\", sep=\";\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"./data/labeledEligibilitySample_parsed.csv\", sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer = vectorizer.fit(df[\"conditions parsed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(df[\"conditions parsed\"])\n",
    "# X = np.hstack((X, df[\"interventions\"].as_matrix(), df[\"diagnosis\"].as_matrix()))\n",
    "y = df[\"label\"].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.2, random_state=1968)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tr, y_tr, test_size=0.33, random_state=1968)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_params = {\n",
    "#     \"C\": np.logspace(0.1, 100, 10)\n",
    "# }\n",
    "\n",
    "# model = GridSearchCV(\n",
    "#         estimator=LogisticRegression(),\n",
    "#         param_grid=logreg_params,\n",
    "#         scoring=\"roc_auc\",\n",
    "#         cv=KFold(n_splits=7),\n",
    "#         verbose=1,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "# model.fit(X_train, y_train)\n",
    "# print(\"Score = {}\\nParams = {}\".format(model.best_score_, model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.023292992280754, validation roc-auc=0.842055303776486\n",
      "C=10.209394837076797, validation roc-auc=0.8463415308096158\n",
      "C=101.85913880541169, validation roc-auc=0.8469089739315917\n",
      "C=1016.2486928706949, validation roc-auc=0.846470026057543\n",
      "C=10139.1138573668, validation roc-auc=0.8462386396061242\n",
      "C=101157.94542598983, validation roc-auc=0.8462736434247633\n",
      "C=1009252.8860766834, validation roc-auc=0.8462769325384691\n",
      "C=10069316.688518044, validation roc-auc=0.8462992691349545\n",
      "C=100461579.02783968, validation roc-auc=0.8461389225012287\n",
      "C=1002305238.0778984, validation roc-auc=0.8462804222177985\n",
      "C=10000000000.0, validation roc-auc=0.8462495092322541\n"
     ]
    }
   ],
   "source": [
    "c_options = np.logspace(0.01, 10, 11)\n",
    "models = []\n",
    "for c in c_options:\n",
    "    model = LogisticRegression(C=c)\n",
    "    model.fit(X_train, y_train)\n",
    "    roc_score = roc_auc_score(model.predict(X_valid), y_valid)\n",
    "    print(\"C={}, validation roc-auc={}\".format(c, roc_score))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее значение на валидации — `C=101.85913880541169, validation roc-auc=0.8469089739315917` (хотя они все примерно одинаковые)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468988349512006"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models[2]\n",
    "y_pred = best_model.predict(X_test)\n",
    "roc_auc_score(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
